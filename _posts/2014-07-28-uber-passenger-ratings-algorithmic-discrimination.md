---
id: 1392
title: 'Uber passenger ratings and algorithmic discrimination'
date: '2014-07-28T00:59:26-07:00'
author: 'Parker Higgins'
layout: post
guid: 'https://parkerhiggins.net/?p=1392'
permalink: /2014/07/uber-passenger-ratings-algorithmic-discrimination/
categories:
    - Uncategorized
tags:
    - algorithms
    - uber
---

For a few hours today, Uber users could view their passenger rating thanks to [a how-to posted by Aaron Landy](https://medium.com/@aaln/how-to-find-your-uber-passenger-rating-4aa1d9cc927f). ((Aaron happens to be [Julie Samuels’s cousin](https://twitter.com/aalndy/status/493588974972055554).)) Uber gives both passengers and drivers ratings, probably by averaging the post-ride ratings each gets, and they affect whether riders can get picked up and whether drivers keep their jobs.

Passenger ratings like these raise two kinds of concerns: first, that opaque and inaccessible metrics don’t allow for recourse or even explanation; and second that driver ratings aren’t very consistent or reliable raw material for those metrics.

You hear stories from people who [missed a pickup because of buggy notifications](https://twitter.com/starkness/status/493650431457767428), for example, and those people all of a sudden just can’t catch a cab. Any kind of technical error can skew the ratings, but because they’re invisible they’re also treated as infallible.

But more fundamentally, when you condition catching a cab on how drivers rate passengers, you run the risk of amplifying human biases. We may think it’s ok for a rude or inconsiderate passenger to get low ratings, but what is the effect on people who speak with an accent, or people who have been drinking, or get picked up or dropped off outside a gay bar, or pregnant or nursing women?

It’s easy for somebody not used to being marginalized to say these ratings just provide an incentive to be kind and respectful. But it’s only from a position of privilege that one can know kindness and respect will result in a favorable rating.

It may seem strange to focus this much scrutiny on Uber, which is admittedly a luxury. But the questions raised come up in more basic issues of algorithmic discrimination. Just look at the metrics, [currently being examined by New York regulators](http://dealbook.nytimes.com/2014/06/15/bank-account-screening-tool-is-scrutinized-as-excessive/), that deny people even basic bank accounts.

Turning back to Uber: Passengers don’t know if drivers are trained to rate consistently or whether those ratings get audited or normalized in some way. Tech like Uber could be helping to erase discrimination in transportation, but if it’s not done thoughtfully it could just as easily entrench it much further.

*Note: I originally wrote a version of this in response to a request for comment from The Guardian. [That story has been published](http://www.theguardian.com/technology/2014/jul/28/are-ubers-passenger-ratings-big-data) and incorporates quotes from the original that appear here too.*